{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset Datasets/merged_tp_precip_wind_fmc_Idaho.csv contains (row, column) = \n",
      "(34939, 16)\n",
      "The dataset Datasets/fuel_with_fips.csv contains (row, column) = \n",
      "(67172, 9)\n",
      "The referral county Idaho has 6 rows of data in the Datasets/fuel_with_fips.csv\n",
      "referral_dataset with fips 16049 = (6, 9)\n",
      "Add data to the original 2010-07-28 00:00:00 <- 2010-08-02  delta days 5: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-07-27 00:00:00 <- 2010-08-02  delta days 6: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-07-28 00:00:00 <- 2010-08-02  delta days 5: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-07-28 00:00:00 <- 2010-08-02  delta days 5: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-07-28 00:00:00 <- 2010-08-02  delta days 5: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-07-26 00:00:00 <- 2010-08-02  delta days 7: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-07-26 00:00:00 <- 2010-08-02  delta days 7: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-08-10 00:00:00 <- 2010-08-09  delta days -1: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-10 00:00:00 <- 2010-08-09  delta days -1: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-06 00:00:00 <- 2010-08-09  delta days 3: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-09 00:00:00 <- 2010-08-09  delta days 0: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-07 00:00:00 <- 2010-08-09  delta days 2: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-12 00:00:00 <- 2010-08-09  delta days -3: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-07 00:00:00 <- 2010-08-09  delta days 2: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-03 00:00:00 <- 2010-08-02  delta days -1: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-08-02 00:00:00 <- 2010-08-02  delta days 0: \n",
      "percent = 159.0\n",
      "Add data to the original 2010-08-10 00:00:00 <- 2010-08-09  delta days -1: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-10 00:00:00 <- 2010-08-09  delta days -1: \n",
      "percent = 123.625\n",
      "Add data to the original 2010-08-04 00:00:00 <- 2010-08-02  delta days -2: \n",
      "percent = 159.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# Define the important variables here\n",
    "\n",
    "target = {\n",
    "    \"fips\": 16049,\n",
    "    \"target_county_name\": \"Idaho\",\n",
    "    \"date_column_name\": \"DATE\",\n",
    "    \"datetime_format\": \"%Y%m%d\",\n",
    "    \"file_name\": \"\",\n",
    "    \"target_data_field_name\": \"prcp\"\n",
    "}\n",
    "target['file_name'] = f\"Datasets/merged_tp_precip_wind_fmc_{target['target_county_name']}.csv\"\n",
    "\n",
    "# Use the adjacent county of the target county to find referral data like aws or fmc\n",
    "# Use the following link to find the adjacent county\n",
    "# https://gis.data.ca.gov/datasets/8713ced9b78a4abb97dc130a691a8695/explore?location=39.765076%2C-121.456785%2C8.00\n",
    "\n",
    "# prcp\n",
    "prcp_referral = {\n",
    "    \"fips_code\": 16049,\n",
    "    \"referral_country_name\": \"Idaho\",\n",
    "    \"fips_column_name\": \"county_fips\",\n",
    "    \"date_column_name\": \"date\",\n",
    "    \"datetime_format\": \"%Y%m%d\",\n",
    "    \"file_name\": \"Datasets/tp_zipcode_county.csv\",\n",
    "    \"data_fields_to_be_copied\": [\"prcp\", \"tmax\", \"tmin\", \"tavg\"]\n",
    "}\n",
    "\n",
    "# Wind\n",
    "wind_aws_referral = {\n",
    "    \"fips_code\": 16049,\n",
    "    \"referral_country_name\": \"Idaho\",\n",
    "    \"fips_column_name\": \"fips\",\n",
    "    \"date_column_name\": \"date\",\n",
    "    \"datetime_format\": \"%Y-%m-%d\",\n",
    "    \"file_name\": \"Datasets/wind_with_fips.csv\",\n",
    "    \"data_fields_to_be_copied\": [\"aws\"]\n",
    "}\n",
    "\n",
    "# fuel moisture content \n",
    "fmc_referral = {\n",
    "    \"fips_code\": 16049,\n",
    "    \"referral_country_name\": \"Idaho\",\n",
    "    \"fips_column_name\": \"fips\",\n",
    "    \"date_column_name\": \"date\",\n",
    "    \"datetime_format\": \"%Y-%m-%d\",\n",
    "    \"file_name\": \"Datasets/fuel_with_fips.csv\",\n",
    "    \"data_fields_to_be_copied\": [\"percent\"]\n",
    "}\n",
    "\n",
    "\n",
    "# When compare the date between data sets, compare the following day delta \n",
    "date_delta_range = [0, -1, 1, -2, 2, -3, 3, -4, 4, -5, 5, -6, 6, -7, 7, -8, 8, -9, 9, -10, 10, -11, 11, -12, 12, -13, 13, -14, 14, -15, 15, -16, 16, -17, 17, -18, 18, -19, 19, -20, 20]\n",
    "\n",
    "# Extract the whole volume \n",
    "def filter_dataframe_by_value(df, column_name, value_to_find):\n",
    "    filtered_rows = df[df[column_name] == value_to_find]\n",
    "    return filtered_rows\n",
    "\n",
    "def load_csv(target):\n",
    "    # Load the target dataset\n",
    "    target_dataset = pd.read_csv(target['file_name']) #, index_col=target['date_column_name'])\n",
    "    print(f\"The dataset {target['file_name']} contains (row, column) = \")\n",
    "    print(target_dataset.shape)\n",
    "    return target_dataset\n",
    "\n",
    "def save_csv(target, target_dataset):  \n",
    "    # Drop all the index columns unnamed: 0 before saving \n",
    "    target_dataset.drop(target_dataset.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    # Save the data to its original file\n",
    "    target_dataset.to_csv(target['file_name'])\n",
    "    print(f\"Saved to {target['file_name']}\")\n",
    "\n",
    "# Copy the matched column from the referral dataset to the target dataset\n",
    "# The match key is the date. Note the date column might have different names\n",
    "# The datetime must be close to each other between two datasets\n",
    "def merge_dataframes_on_near_date(target_df, referral_df, \n",
    "                            referral):\n",
    "\n",
    "    #referral_df.head()\n",
    "    \n",
    "    # Sort the referral data set by Date, ascending \n",
    "    referral_df = referral_df.sort_values(referral['date_column_name'])\n",
    "\n",
    "    for index1, row1 in target_df.iterrows():\n",
    "        # Get the target datetime. \n",
    "        # Need to convert the string to a datetime object\n",
    "        row1_datetime = datetime.strptime(str(row1[target['date_column_name']]),  target['datetime_format'])\n",
    "\n",
    "        row1_near_date = []\n",
    "        for i in date_delta_range:\n",
    "\n",
    "            # Convert the day to int in order to compare with the referral_df.date, which is loaded as int by default\n",
    "            next_day = row1_datetime + timedelta( days = i)\n",
    "            #referral_next_day = int(next_day.strftime(referral['datetime_format']))\n",
    "            referral_next_day = next_day.strftime(referral['datetime_format'])\n",
    "            # If it is int ( not a string), convert to int as it is fast\n",
    "            if  referral_df.dtypes[referral['date_column_name']] == 'int':\n",
    "                referral_next_day = int(referral_next_day)\n",
    "            row1_near_date.append( referral_next_day)\n",
    "\n",
    "            # Find in the referral dataframe by date\n",
    "            found_df = referral_df[referral_df[referral['date_column_name']] == referral_next_day]\n",
    "            if (found_df.size > 0):\n",
    "                print(f\"Add data to the original {row1_datetime} <- {referral_next_day}  delta days {i}: \")\n",
    "                for f in referral[\"data_fields_to_be_copied\"]:\n",
    "                    # Found the value in the first cell and assign to the target dataframe\n",
    "                    target_df.at[index1, f] = found_df.iloc[0][f]\n",
    "                    print(f\"{f} = {target_df.at[index1, f]}\")\n",
    "                \n",
    "                # Finished fo this date\n",
    "                break;\n",
    "\n",
    "#\n",
    "# Main program starts here\n",
    "#\n",
    "def merge_data_referral_to_target(target, referral): \n",
    "\n",
    "    # Load the target dataset\n",
    "    target_dataset = load_csv(target)\n",
    "\n",
    "    # Initial the referral dataset from a csv\n",
    "    referral_dataset = load_csv(referral)\n",
    "\n",
    "    # Check if the county exists in the referral dataset\n",
    "    referral_count = referral_dataset['county'].str.contains(referral['referral_country_name']).sum()\n",
    "    print(f\"The referral county {referral['referral_country_name']} has {referral_count} rows of data in the {referral['file_name']}\")  \n",
    "    # If no data is found, exit the program\n",
    "    if ( int(referral_count) <= 0):\n",
    "        print(\"The county doesn't exist in the referral dataset. Exits the program.\")\n",
    "        return \n",
    "    \n",
    "    # Create a new data frame containing only rows with the specific value\n",
    "    referral_dataset_fips_only = filter_dataframe_by_value(referral_dataset, referral['fips_column_name'], referral['fips_code'])\n",
    "    print(f\"referral_dataset with fips {referral['fips_code']} = {referral_dataset_fips_only.shape}\")\n",
    "\n",
    "                \n",
    "    # Add the new data from the referral dataset to the target dataset\n",
    "    # merge_dataframes_on_match\n",
    "    merge_dataframes_on_near_date(target_dataset, referral_dataset_fips_only, referral)\n",
    "\n",
    "    # Save the data to its original file\n",
    "    save_csv(target, target_dataset)\n",
    "\n",
    "def generate_csv_for_fips(target):\n",
    "\n",
    "    fire_data = pd.read_csv(\"Datasets/aggregated_wildfire.csv\")\n",
    "    fire_data.head()\n",
    "    # Create a new DataFrame containing only rows with the specific value\n",
    "    firedata_fips = filter_dataframe_by_value(fire_data, 'FIPS', target[\"fips\"])\n",
    "    #new columns for merged features\n",
    "    firedata_fips[\"tmax\"] = 0\n",
    "    firedata_fips[\"tmin\"] = 0\n",
    "    firedata_fips[\"tavg\"] = 0\n",
    "    firedata_fips[\"prcp\"] = 0\n",
    "    firedata_fips[\"aws\"] = 0\n",
    "    firedata_fips[\"fmc\"] = 0\n",
    "    save_csv(target, firedata_fips)\n",
    "\n",
    "#\n",
    "# Main program\n",
    "# \n",
    "# generate_csv_for_fips(target)\n",
    "#merge_data_referral_to_target(target, prcp_referral) \n",
    "#merge_data_referral_to_target(target, wind_aws_referral)\n",
    "merge_data_referral_to_target(target, fmc_referral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
