{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# When compare the date between data sets, compare the following day delta \n",
    "days_delta_range = [0, -1, 1, -2, 2, -3, 3, -4, 4, -5, 5, -6, 6, -7, 7, -8, 8, -9, 9, -10, 10, -11, 11, -12, 12, -13, 13, -14, 14, -15, 15, -16, 16, -17, 17, -18, 18, -19, 19, -20, 20]\n",
    "\n",
    "# Extract the whole volume \n",
    "def filter_dataframe_by_value(df, column_name, value_to_find):\n",
    "    filtered_rows = df[df[column_name] == value_to_find]\n",
    "    return filtered_rows\n",
    "\n",
    "def load_csv(target):\n",
    "    # Load the target dataset\n",
    "    target_dataset = pd.read_csv(target['file_name']) #, index_col=target['date_column_name'])\n",
    "    print(f\"The dataset {target['file_name']} contains (row, column) = \")\n",
    "    print(target_dataset.shape)\n",
    "    return target_dataset\n",
    "\n",
    "def save_csv(target, target_dataset):  \n",
    "    # Drop all the index columns unnamed: 0 before saving \n",
    "    target_dataset.drop(target_dataset.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    # Save the data to its original file\n",
    "    target_dataset.to_csv(target['file_name'])\n",
    "    print(f\"Saved to {target['file_name']}\")\n",
    "\n",
    "# Copy the matched column from the referral dataset to the target dataset\n",
    "# The match key is the date. Note the date column might have different names\n",
    "# The datetime must be close to each other between two datasets\n",
    "def merge_dataframes_on_near_date(target_df, target, \n",
    "                                  referral_df, referral):\n",
    "\n",
    "    #referral_df.head()\n",
    "    \n",
    "    # Sort the referral data set by Date, ascending \n",
    "    referral_df = referral_df.sort_values(referral['date_column_name'])\n",
    "\n",
    "    for index1, row1 in target_df.iterrows():\n",
    "        # Get the target datetime. \n",
    "        # Need to convert the string to a datetime object\n",
    "        row1_datetime = datetime.strptime(str(row1[target['date_column_name']]),  target['datetime_format'])\n",
    "\n",
    "        row1_near_date = []\n",
    "        for i in days_delta_range:\n",
    "\n",
    "            # Convert the day to int in order to compare with the referral_df.date, which is loaded as int by default\n",
    "            next_day = row1_datetime + timedelta( days = i)\n",
    "            #referral_next_day = int(next_day.strftime(referral['datetime_format']))\n",
    "            referral_next_day = next_day.strftime(referral['datetime_format'])\n",
    "            # If it is int ( not a string), convert to int as it is fast\n",
    "            if  referral_df.dtypes[referral['date_column_name']] == 'int':\n",
    "                referral_next_day = int(referral_next_day)\n",
    "            row1_near_date.append( referral_next_day)\n",
    "\n",
    "            # Find in the referral dataframe by date\n",
    "            found_df = referral_df[referral_df[referral['date_column_name']] == referral_next_day]\n",
    "            if (found_df.size > 0):\n",
    "                print(f\"Add data to the original {row1_datetime} <- {referral_next_day}  delta days {i}: \")\n",
    "                for f in referral[\"data_fields_to_be_copied\"]:\n",
    "                    # Found the value in the first cell and assign to the target dataframe\n",
    "                    # The target columne name might be different from the referral's. \n",
    "                    ### Hard code for now\n",
    "                    target_column_name = f;\n",
    "                    if target_column_name == \"percent\":\n",
    "                        target_column_name = \"fmc\"\n",
    "\n",
    "                    target_df.at[index1, target_column_name] = found_df.iloc[0][f]\n",
    "                    print(f\"{f} = {target_df.at[index1, target_column_name]}\")\n",
    "                \n",
    "                # Finished fo this date\n",
    "                break;\n",
    "\n",
    "#\n",
    "# Main program starts here\n",
    "#\n",
    "def merge_data_referral_to_target(target, referral): \n",
    "\n",
    "    # Load the target dataset\n",
    "    target_dataset = load_csv(target)\n",
    "\n",
    "    # Initial the referral dataset from a csv\n",
    "    referral_dataset = load_csv(referral)\n",
    "\n",
    "    # Check if the county exists in the referral dataset\n",
    "    referral_count = referral_dataset['county'].str.contains(referral['referral_county_name']).sum()\n",
    "    print(f\"The referral county {referral['referral_county_name']} has {referral_count} rows of data in the {referral['file_name']}\")  \n",
    "    # If no data is found, exit the program\n",
    "    if ( int(referral_count) <= 0):\n",
    "        print(\"The county doesn't exist in the referral dataset. Exits the program.\")\n",
    "        return \n",
    "    \n",
    "    # Create a new data frame containing only rows with the specific value\n",
    "    referral_dataset_fips_only = filter_dataframe_by_value(referral_dataset, referral['fips_column_name'], referral['fips_code'])\n",
    "    print(f\"referral_dataset with fips {referral['fips_code']} = {referral_dataset_fips_only.shape}\")\n",
    "\n",
    "                \n",
    "    # Add the new data from the referral dataset to the target dataset\n",
    "    # merge_dataframes_on_match\n",
    "    merge_dataframes_on_near_date(target_dataset, target, \n",
    "                                  referral_dataset_fips_only, referral)\n",
    "\n",
    "    # Save the data to its original file\n",
    "    save_csv(target, target_dataset)\n",
    "\n",
    "def generate_csv_for_fips(target):\n",
    "\n",
    "    fire_data = pd.read_csv(\"Datasets/aggregated_wildfire.csv\")\n",
    "    fire_data.head()\n",
    "    # Create a new DataFrame containing only rows with the specific value\n",
    "    firedata_fips = filter_dataframe_by_value(fire_data, 'FIPS', target[\"fips\"])\n",
    "    #new columns for merged features\n",
    "    firedata_fips[\"tmax\"] = 0\n",
    "    firedata_fips[\"tmin\"] = 0\n",
    "    firedata_fips[\"tavg\"] = 0\n",
    "    firedata_fips[\"prcp\"] = 0\n",
    "    firedata_fips[\"aws\"] = 0\n",
    "    firedata_fips[\"fmc\"] = 0\n",
    "    save_csv(target, firedata_fips)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
