{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# Define the important variables here\n",
    "\n",
    "target = {\n",
    "    \"fips\": 6009,\n",
    "    \"target_county_name\": \"Calaveras\",\n",
    "    \"target_data_file_name\": \"\",\n",
    "    \"target_data_field_name\": \"fmc\"\n",
    "}\n",
    "target['target_data_file_name'] = f\"Datasets/merged_tp_precip_wind_fmc_{target['target_county_name']}.csv\"\n",
    "\n",
    "# Use the adjacent county of the target county to find referral data like aws or fmc\n",
    "# Use the following link to find the adjacent county\n",
    "# https://gis.data.ca.gov/datasets/8713ced9b78a4abb97dc130a691a8695/explore?location=39.765076%2C-121.456785%2C8.00\n",
    "referral = {\n",
    "    \"referral_fips\": 6005,\n",
    "    \"referral_country_name\": \"Amador\",\n",
    "    \"referral_data_file_name\": \"Datasets/fuel_with_fips.csv\",\n",
    "    \"referral_data_field_name\": \"percent\"\n",
    "}\n",
    "\n",
    "#\n",
    "# Main program starts here\n",
    "#\n",
    "# Load the target dataset\n",
    "target_dataset = pd.read_csv(target['target_data_file_name'])\n",
    "print(f\"The dataset {target['target_data_file_name']} contains (row, column) = \")\n",
    "print(target_dataset.shape)\n",
    "\n",
    "# Initial the referral dataset from a csv\n",
    "referral_dataset = pd.read_csv(referral['referral_data_file_name'])\n",
    "\n",
    "# Check if the county exists in the referral dataset\n",
    "referral_count = referral_dataset['county'].str.contains(referral['referral_country_name']).sum()\n",
    "print(f\"The referral county {referral['referral_country_name']} has {referral_count} rows of data in the {referral['referral_data_file_name']}\")  \n",
    "# If not data found, exit the program\n",
    "if ( int(referral_count) <= 0):\n",
    "    #quit()\n",
    "    raise SystemExit(\"The county doesn't exist in the referral dataset. Exits the program. \")\n",
    "    \n",
    "# Extract the whole volume \n",
    "def filter_dataframe_by_value(df, column_name, value_to_find):\n",
    "    filtered_rows = df[df[column_name] == value_to_find]\n",
    "    return filtered_rows\n",
    "\n",
    "# Create a new DataFrame containing only rows with the specific value\n",
    "referral_dataset_fips_only = filter_dataframe_by_value(referral_dataset, 'fips', referral['referral_fips'])\n",
    "\n",
    "# Copy the matched column from the referral dataset to the target dataset\n",
    "# the datetime must be close to each other between two datasets\n",
    "def merge_dataframes_on_match(df1, df2, df1_column1, df2_column1, referral_data_field_name, target_data_field_name):\n",
    "    for index1, row1 in df1.iterrows():\n",
    "        # Convert to a datatime object\n",
    "        row1_datetime = datetime.strptime(str(row1[df1_column1]),  \"%Y%m%d\")\n",
    "        # Iniatize the second datetime\n",
    "        row2_datetime = row1_datetime; \n",
    "        data_to_fill = -1\n",
    "        data_to_fill_datetime = row2_datetime\n",
    "        data_to_fill_delta_days = 0\n",
    "        for index2, row2 in df2.iterrows():\n",
    "            row2_datetime = datetime.strptime(row2[df2_column1], \"%Y-%m-%d\")\n",
    "            delta_days = (row1_datetime - row2_datetime).days\n",
    "            if (delta_days < 0):\n",
    "                delta_days = -delta_days\n",
    "                \n",
    "            # print(f\"Found a row with diff days {delta_days} between {row1_datetime} and {row2_datetime}\")\n",
    "            if (delta_days < 100):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "            if (delta_days < 50):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "            if (delta_days < 25):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "            if (delta_days < 10):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "            if (delta_days < 5):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "            if (delta_days < 3):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "            if (delta_days < 1):\n",
    "                data_to_fill = row2[referral_data_field_name]\n",
    "                data_to_fill_datetime = row2_datetime\n",
    "                data_to_fill_delta_days = delta_days\n",
    "                break   \n",
    "\n",
    "        if (data_to_fill != -1):\n",
    "            print(f\"Add data to the original {row1_datetime} <- {data_to_fill_datetime} - {data_to_fill_delta_days} days: {data_to_fill}\")\n",
    "            df1.at[index1, target_data_field_name] = data_to_fill\n",
    "                \n",
    "# Add the new data from the referral dataset to the target dataset\n",
    "merge_dataframes_on_match(target_dataset, referral_dataset_fips_only.sort_values(\"date\"), \n",
    "                          'DATE', 'date', \n",
    "                          referral['referral_data_field_name'], target['target_data_field_name'])\n",
    "\n",
    "# Save the data to its original file\n",
    "target_dataset.to_csv(target['target_data_file_name'])\n",
    "print(f\"Saved to {target['target_data_file_name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
