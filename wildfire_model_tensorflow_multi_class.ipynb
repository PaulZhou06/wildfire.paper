{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[reference script](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)"
      ],
      "metadata": {
        "id": "iTGn2Hjxs5E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Package and Data\n",
        "\n"
      ],
      "metadata": {
        "id": "38bH4kOQqgx0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ojsMp4kVa2",
        "outputId": "0044fdd8-960d-43d7-e85a-22f6b27167d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tempfile\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the dataset\n"
      ],
      "metadata": {
        "id": "yAQLPt6DgLAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load your dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the path to your CSV file\n",
        "# Make sure your CSV file contains features and a target column\n",
        "# For example, X as features and y as the target column\n",
        "# Modify this part according to your actual dataset structure\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Wildfire/Datasets/merged_tp_precip_wind_fmc_all.csv\")\n",
        "data.dropna(inplace = True)\n",
        "data.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
        "data.drop([\"START_DATE\"], axis = 1, inplace = True)\n",
        "data.drop([\"END_DATE\"], axis = 1, inplace = True)\n",
        "#data.drop([\"DATE\"], axis = 1, inplace = True)\n",
        "data[\"DATE\"] = data[\"DATE\"].astype(float)\n"
      ],
      "metadata": {
        "id": "tNCZl80HArCa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(\"FIRE_SIZE_CLASS\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ApYkX6G7EvYL",
        "outputId": "2c10d4a8-2546-48c4-826c-0c8b1625f02e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 LATITUDE  LONGITUDE    FIPS    DATE    tmax    tmin    tavg  \\\n",
              "FIRE_SIZE_CLASS                                                                \n",
              "0                  197739     197739  197739  197739  197739  197739  197739   \n",
              "1                   16518      16518   16518   16518   16518   16518   16518   \n",
              "2                    4063       4063    4063    4063    4063    4063    4063   \n",
              "\n",
              "                   prcp     aws     fmc  \n",
              "FIRE_SIZE_CLASS                          \n",
              "0                197739  197739  197739  \n",
              "1                 16518   16518   16518  \n",
              "2                  4063    4063    4063  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3336f550-e54e-4856-a3bc-4b0534632ac3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>FIPS</th>\n",
              "      <th>DATE</th>\n",
              "      <th>tmax</th>\n",
              "      <th>tmin</th>\n",
              "      <th>tavg</th>\n",
              "      <th>prcp</th>\n",
              "      <th>aws</th>\n",
              "      <th>fmc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIRE_SIZE_CLASS</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "      <td>197739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "      <td>16518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "      <td>4063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3336f550-e54e-4856-a3bc-4b0534632ac3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3336f550-e54e-4856-a3bc-4b0534632ac3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3336f550-e54e-4856-a3bc-4b0534632ac3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d2811b8-13b0-48ae-863f-dfcd34783ac4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d2811b8-13b0-48ae-863f-dfcd34783ac4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d2811b8-13b0-48ae-863f-dfcd34783ac4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-classification of the dataset with our own defined arces size"
      ],
      "metadata": {
        "id": "gpx-MHEygTC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the ranges\n",
        "def classify_ranges(df, column_name, ranges, classification_column):\n",
        "    for range_name, range_values in ranges.items():\n",
        "        df.loc[df[column_name].between(*range_values), classification_column] = range_name\n",
        "\n",
        "# Redefine the classification\n",
        "classification_ranges = {\n",
        "    'A': (0, 99),\n",
        "    'B': (99.000000000001, 999),\n",
        "    'C': (999.000000000001, 99999999999999)\n",
        "}\n",
        "# Creating a new column to store the classifications\n",
        "classify_ranges(data, 'FIRE_SIZE', classification_ranges, 'FIRE_SIZE_CLASS')\n",
        "data.drop([\"FIRE_SIZE\"], axis = 1, inplace = True)\n",
        "data.groupby(\"FIRE_SIZE_CLASS\").count()\n",
        "data['FIRE_SIZE_CLASS'] = data['FIRE_SIZE_CLASS'].replace({'A':0 , 'B':1 , 'C':2 ,'D':3 , 'E':4 , 'F':5 , 'G':6 })"
      ],
      "metadata": {
        "id": "V7MvyopPG1BN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feedforward NN (afully connected neural network) for multi-class classification**"
      ],
      "metadata": {
        "id": "kY_-r75p56FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define your neural network model for 7-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDZTWzEq5DD1",
        "outputId": "6b03dbc1-82c9-4db8-ef26-5deb6b568f6d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5458/5458 [==============================] - 8s 1ms/step - loss: 0.3475 - accuracy: 0.9044 - val_loss: 0.3280 - val_accuracy: 0.9065\n",
            "Epoch 2/10\n",
            "5458/5458 [==============================] - 8s 2ms/step - loss: 0.3238 - accuracy: 0.9058 - val_loss: 0.3186 - val_accuracy: 0.9065\n",
            "Epoch 3/10\n",
            "5458/5458 [==============================] - 8s 1ms/step - loss: 0.3167 - accuracy: 0.9058 - val_loss: 0.3120 - val_accuracy: 0.9066\n",
            "Epoch 4/10\n",
            "5458/5458 [==============================] - 8s 1ms/step - loss: 0.3101 - accuracy: 0.9058 - val_loss: 0.3085 - val_accuracy: 0.9056\n",
            "Epoch 5/10\n",
            "5458/5458 [==============================] - 8s 2ms/step - loss: 0.3058 - accuracy: 0.9058 - val_loss: 0.3043 - val_accuracy: 0.9062\n",
            "Epoch 6/10\n",
            "5458/5458 [==============================] - 10s 2ms/step - loss: 0.3020 - accuracy: 0.9061 - val_loss: 0.3093 - val_accuracy: 0.9057\n",
            "Epoch 7/10\n",
            "5458/5458 [==============================] - 8s 1ms/step - loss: 0.2985 - accuracy: 0.9060 - val_loss: 0.2996 - val_accuracy: 0.9069\n",
            "Epoch 8/10\n",
            "5458/5458 [==============================] - 8s 2ms/step - loss: 0.2957 - accuracy: 0.9063 - val_loss: 0.2981 - val_accuracy: 0.9067\n",
            "Epoch 9/10\n",
            "5458/5458 [==============================] - 8s 1ms/step - loss: 0.2926 - accuracy: 0.9066 - val_loss: 0.2934 - val_accuracy: 0.9060\n",
            "Epoch 10/10\n",
            "5458/5458 [==============================] - 8s 1ms/step - loss: 0.2896 - accuracy: 0.9066 - val_loss: 0.2899 - val_accuracy: 0.9071\n",
            "1365/1365 [==============================] - 1s 946us/step - loss: 0.2899 - accuracy: 0.9071\n",
            "Test Loss: 0.2899, Test Accuracy: 0.9071\n",
            "1365/1365 [==============================] - 1s 858us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     39563\n",
            "           1       0.55      0.05      0.09      3286\n",
            "           2       0.40      0.03      0.05       815\n",
            "\n",
            "    accuracy                           0.91     43664\n",
            "   macro avg       0.62      0.36      0.37     43664\n",
            "weighted avg       0.87      0.91      0.87     43664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FNN**\n",
        "Add more hidden layers and increase the number of neurons in each layer."
      ],
      "metadata": {
        "id": "qZFU7XwJ6dPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define your neural network model for 7-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),  # Additional hidden layer\n",
        "    tf.keras.layers.Dense(32, activation='relu'),  # Additional hidden layer\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPQDFFNb6fT4",
        "outputId": "c7e56ccc-ae57-49d2-acc7-fcaf3bc4f018"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "5458/5458 [==============================] - 15s 3ms/step - loss: 0.3376 - accuracy: 0.9054 - val_loss: 0.3184 - val_accuracy: 0.9065\n",
            "Epoch 2/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.3129 - accuracy: 0.9059 - val_loss: 0.3079 - val_accuracy: 0.9065\n",
            "Epoch 3/15\n",
            "5458/5458 [==============================] - 15s 3ms/step - loss: 0.2976 - accuracy: 0.9060 - val_loss: 0.2931 - val_accuracy: 0.9074\n",
            "Epoch 4/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2840 - accuracy: 0.9070 - val_loss: 0.2835 - val_accuracy: 0.9080\n",
            "Epoch 5/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2746 - accuracy: 0.9078 - val_loss: 0.2703 - val_accuracy: 0.9088\n",
            "Epoch 6/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2675 - accuracy: 0.9087 - val_loss: 0.2664 - val_accuracy: 0.9097\n",
            "Epoch 7/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2617 - accuracy: 0.9096 - val_loss: 0.2589 - val_accuracy: 0.9113\n",
            "Epoch 8/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2572 - accuracy: 0.9100 - val_loss: 0.2587 - val_accuracy: 0.9105\n",
            "Epoch 9/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2522 - accuracy: 0.9113 - val_loss: 0.2584 - val_accuracy: 0.9101\n",
            "Epoch 10/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2480 - accuracy: 0.9119 - val_loss: 0.2483 - val_accuracy: 0.9132\n",
            "Epoch 11/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2433 - accuracy: 0.9127 - val_loss: 0.2460 - val_accuracy: 0.9132\n",
            "Epoch 12/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2412 - accuracy: 0.9130 - val_loss: 0.2436 - val_accuracy: 0.9134\n",
            "Epoch 13/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2372 - accuracy: 0.9142 - val_loss: 0.2378 - val_accuracy: 0.9149\n",
            "Epoch 14/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2331 - accuracy: 0.9148 - val_loss: 0.2367 - val_accuracy: 0.9143\n",
            "Epoch 15/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2306 - accuracy: 0.9150 - val_loss: 0.2376 - val_accuracy: 0.9148\n",
            "1365/1365 [==============================] - 2s 1ms/step - loss: 0.2376 - accuracy: 0.9148\n",
            "Test Loss: 0.2376, Test Accuracy: 0.9148\n",
            "1365/1365 [==============================] - 2s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.96     39563\n",
            "           1       0.66      0.15      0.24      3286\n",
            "           2       0.67      0.27      0.39       815\n",
            "\n",
            "    accuracy                           0.91     43664\n",
            "   macro avg       0.75      0.47      0.53     43664\n",
            "weighted avg       0.90      0.91      0.89     43664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FNN** - More recalls\n",
        "To increase the recall of Class B and Class C, adjust the class weights during model training to give more importance to these minority classes. We should assign higher weights to the minority classes."
      ],
      "metadata": {
        "id": "wzK9k5epBzxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Calculate class weights to give more importance to minority classes (B and C)\n",
        "class_weights = {0: 1.0, 1: 5.0, 2: 5.0}  # Adjust the weights as needed\n",
        "\n",
        "# Define your neural network model for 7-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),  # Additional hidden layer\n",
        "    tf.keras.layers.Dense(32, activation='relu'),  # Additional hidden layer\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Compile the model with class weights\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with class weights\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It4JDfpEB22R",
        "outputId": "d2223fa0-dfac-496a-925a-faf7415961e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "5458/5458 [==============================] - 19s 3ms/step - loss: 1.0233 - accuracy: 0.8761 - val_loss: 0.4536 - val_accuracy: 0.8680\n",
            "Epoch 2/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.9343 - accuracy: 0.8567 - val_loss: 0.4034 - val_accuracy: 0.8596\n",
            "Epoch 3/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.8794 - accuracy: 0.8492 - val_loss: 0.4075 - val_accuracy: 0.8585\n",
            "Epoch 4/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.8336 - accuracy: 0.8462 - val_loss: 0.4409 - val_accuracy: 0.8319\n",
            "Epoch 5/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.8008 - accuracy: 0.8456 - val_loss: 0.4248 - val_accuracy: 0.8304\n",
            "Epoch 6/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.7765 - accuracy: 0.8472 - val_loss: 0.4137 - val_accuracy: 0.8251\n",
            "Epoch 7/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.7524 - accuracy: 0.8493 - val_loss: 0.4015 - val_accuracy: 0.8384\n",
            "Epoch 8/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.7334 - accuracy: 0.8488 - val_loss: 0.4022 - val_accuracy: 0.8289\n",
            "Epoch 9/15\n",
            "5458/5458 [==============================] - 14s 2ms/step - loss: 0.7162 - accuracy: 0.8486 - val_loss: 0.3712 - val_accuracy: 0.8443\n",
            "Epoch 10/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.7033 - accuracy: 0.8503 - val_loss: 0.4107 - val_accuracy: 0.8266\n",
            "Epoch 11/15\n",
            "5458/5458 [==============================] - 14s 2ms/step - loss: 0.6883 - accuracy: 0.8521 - val_loss: 0.3586 - val_accuracy: 0.8476\n",
            "Epoch 12/15\n",
            "5458/5458 [==============================] - 14s 2ms/step - loss: 0.6790 - accuracy: 0.8538 - val_loss: 0.3429 - val_accuracy: 0.8564\n",
            "Epoch 13/15\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.6654 - accuracy: 0.8544 - val_loss: 0.3728 - val_accuracy: 0.8395\n",
            "Epoch 14/15\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.6569 - accuracy: 0.8551 - val_loss: 0.3548 - val_accuracy: 0.8501\n",
            "Epoch 15/15\n",
            "5458/5458 [==============================] - 16s 3ms/step - loss: 0.6471 - accuracy: 0.8567 - val_loss: 0.3586 - val_accuracy: 0.8470\n",
            "1365/1365 [==============================] - 3s 2ms/step - loss: 0.3586 - accuracy: 0.8470\n",
            "Test Loss: 0.3586, Test Accuracy: 0.8470\n",
            "1365/1365 [==============================] - 2s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.87      0.92     39563\n",
            "           1       0.31      0.63      0.42      3286\n",
            "           2       0.36      0.65      0.47       815\n",
            "\n",
            "    accuracy                           0.85     43664\n",
            "   macro avg       0.55      0.72      0.60     43664\n",
            "weighted avg       0.91      0.85      0.87     43664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FNN SMOTE\n",
        "(Synthetic Minority Over-sampling Technique) for imbalanced dataset\n",
        "pip install imbalanced-learn\n"
      ],
      "metadata": {
        "id": "FVqUowBFEdjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have already loaded and prepared your data\n",
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define your neural network model for 7-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the resampled data\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPh77iC-EmGw",
        "outputId": "04c32d04-13c1-4dde-8488-3b329e89b16b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14829/14829 [==============================] - 30s 2ms/step - loss: 0.8126 - accuracy: 0.6221 - val_loss: 0.8643 - val_accuracy: 0.6084\n",
            "Epoch 2/10\n",
            "14829/14829 [==============================] - 35s 2ms/step - loss: 0.6865 - accuracy: 0.6944 - val_loss: 0.6995 - val_accuracy: 0.7005\n",
            "Epoch 3/10\n",
            "14829/14829 [==============================] - 35s 2ms/step - loss: 0.6431 - accuracy: 0.7167 - val_loss: 0.7258 - val_accuracy: 0.6629\n",
            "Epoch 4/10\n",
            "14829/14829 [==============================] - 30s 2ms/step - loss: 0.6158 - accuracy: 0.7315 - val_loss: 0.7832 - val_accuracy: 0.6113\n",
            "Epoch 5/10\n",
            "14829/14829 [==============================] - 29s 2ms/step - loss: 0.5957 - accuracy: 0.7417 - val_loss: 0.6926 - val_accuracy: 0.6886\n",
            "Epoch 6/10\n",
            "14829/14829 [==============================] - 30s 2ms/step - loss: 0.5801 - accuracy: 0.7501 - val_loss: 0.6351 - val_accuracy: 0.7187\n",
            "Epoch 7/10\n",
            "14829/14829 [==============================] - 28s 2ms/step - loss: 0.5713 - accuracy: 0.7553 - val_loss: 0.6225 - val_accuracy: 0.7360\n",
            "Epoch 8/10\n",
            "14829/14829 [==============================] - 28s 2ms/step - loss: 0.5617 - accuracy: 0.7608 - val_loss: 0.7128 - val_accuracy: 0.6752\n",
            "Epoch 9/10\n",
            "14829/14829 [==============================] - 29s 2ms/step - loss: 0.5536 - accuracy: 0.7660 - val_loss: 0.5963 - val_accuracy: 0.7399\n",
            "Epoch 10/10\n",
            "14829/14829 [==============================] - 34s 2ms/step - loss: 0.5476 - accuracy: 0.7679 - val_loss: 0.6739 - val_accuracy: 0.6788\n",
            "1365/1365 [==============================] - 2s 1ms/step - loss: 0.6739 - accuracy: 0.6788\n",
            "Test Loss: 0.6739, Test Accuracy: 0.6788\n",
            "1365/1365 [==============================] - 2s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.67      0.80     39563\n",
            "           1       0.18      0.71      0.28      3286\n",
            "           2       0.21      0.81      0.34       815\n",
            "\n",
            "    accuracy                           0.68     43664\n",
            "   macro avg       0.45      0.73      0.47     43664\n",
            "weighted avg       0.90      0.68      0.75     43664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RNN Model**\n",
        "It provides more precisions.\n",
        "RNNs work better for sequence data like time series or text data. They might not be the best choice for tabular data, as they are designed for sequential data. However, if your data has some sequential aspects, you can use a specific type of RNN called Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU) for modeling sequences within the tabular data."
      ],
      "metadata": {
        "id": "D-xmFaAh1oyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define your neural network model with an LSTM layer\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Reshape the input data to match the expected input shape for LSTM\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqOienYMzj4l",
        "outputId": "8529961b-944e-429f-95b0-d890659fbee9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5458/5458 [==============================] - 37s 6ms/step - loss: 0.3615 - accuracy: 0.9054 - val_loss: 0.3341 - val_accuracy: 0.9061\n",
            "Epoch 2/10\n",
            "5458/5458 [==============================] - 42s 8ms/step - loss: 0.3346 - accuracy: 0.9056 - val_loss: 0.3300 - val_accuracy: 0.9063\n",
            "Epoch 3/10\n",
            "5458/5458 [==============================] - 37s 7ms/step - loss: 0.3284 - accuracy: 0.9057 - val_loss: 0.3230 - val_accuracy: 0.9064\n",
            "Epoch 4/10\n",
            "5458/5458 [==============================] - 36s 7ms/step - loss: 0.3234 - accuracy: 0.9058 - val_loss: 0.3211 - val_accuracy: 0.9064\n",
            "Epoch 5/10\n",
            "5458/5458 [==============================] - 37s 7ms/step - loss: 0.3186 - accuracy: 0.9058 - val_loss: 0.3160 - val_accuracy: 0.9064\n",
            "Epoch 6/10\n",
            "5458/5458 [==============================] - 34s 6ms/step - loss: 0.3129 - accuracy: 0.9058 - val_loss: 0.3113 - val_accuracy: 0.9064\n",
            "Epoch 7/10\n",
            "5458/5458 [==============================] - 36s 7ms/step - loss: 0.3069 - accuracy: 0.9059 - val_loss: 0.3042 - val_accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "5458/5458 [==============================] - 36s 7ms/step - loss: 0.3016 - accuracy: 0.9059 - val_loss: 0.3037 - val_accuracy: 0.9068\n",
            "Epoch 9/10\n",
            "5458/5458 [==============================] - 36s 7ms/step - loss: 0.2938 - accuracy: 0.9060 - val_loss: 0.2935 - val_accuracy: 0.9067\n",
            "Epoch 10/10\n",
            "5458/5458 [==============================] - 38s 7ms/step - loss: 0.2872 - accuracy: 0.9066 - val_loss: 0.2832 - val_accuracy: 0.9088\n",
            "1365/1365 [==============================] - 5s 4ms/step - loss: 0.2832 - accuracy: 0.9088\n",
            "Test Loss: 0.2832, Test Accuracy: 0.9088\n",
            "1365/1365 [==============================] - 6s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     39563\n",
            "           1       0.61      0.06      0.11      3286\n",
            "           2       0.67      0.06      0.11       815\n",
            "\n",
            "    accuracy                           0.91     43664\n",
            "   macro avg       0.73      0.37      0.39     43664\n",
            "weighted avg       0.88      0.91      0.87     43664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**\n",
        "CNNs are commonly used for image data, they can also be applied to tabular data when there are spatial relationships among features or if want to capture local patterns."
      ],
      "metadata": {
        "id": "JeEeVxhN2B-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the input data to match the expected input shape for CNN\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Define your neural network model with a CNN layer\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_fQOTVc1_8P",
        "outputId": "2422ee43-b6da-47b5-bbcd-aeb8958b32d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5458/5458 [==============================] - 20s 4ms/step - loss: 0.3478 - accuracy: 0.9052 - val_loss: 0.3316 - val_accuracy: 0.9063\n",
            "Epoch 2/10\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.3282 - accuracy: 0.9057 - val_loss: 0.3266 - val_accuracy: 0.9058\n",
            "Epoch 3/10\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.3196 - accuracy: 0.9056 - val_loss: 0.3153 - val_accuracy: 0.9058\n",
            "Epoch 4/10\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.3129 - accuracy: 0.9058 - val_loss: 0.3086 - val_accuracy: 0.9066\n",
            "Epoch 5/10\n",
            "5458/5458 [==============================] - 16s 3ms/step - loss: 0.3082 - accuracy: 0.9059 - val_loss: 0.3176 - val_accuracy: 0.9052\n",
            "Epoch 6/10\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.3040 - accuracy: 0.9061 - val_loss: 0.3037 - val_accuracy: 0.9059\n",
            "Epoch 7/10\n",
            "5458/5458 [==============================] - 19s 3ms/step - loss: 0.3004 - accuracy: 0.9060 - val_loss: 0.3051 - val_accuracy: 0.9060\n",
            "Epoch 8/10\n",
            "5458/5458 [==============================] - 14s 3ms/step - loss: 0.2979 - accuracy: 0.9061 - val_loss: 0.3007 - val_accuracy: 0.9056\n",
            "Epoch 9/10\n",
            "5458/5458 [==============================] - 15s 3ms/step - loss: 0.2955 - accuracy: 0.9060 - val_loss: 0.2934 - val_accuracy: 0.9064\n",
            "Epoch 10/10\n",
            "5458/5458 [==============================] - 13s 2ms/step - loss: 0.2930 - accuracy: 0.9061 - val_loss: 0.2950 - val_accuracy: 0.9058\n",
            "1365/1365 [==============================] - 2s 1ms/step - loss: 0.2950 - accuracy: 0.9058\n",
            "Test Loss: 0.2950, Test Accuracy: 0.9058\n",
            "1365/1365 [==============================] - 2s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     39563\n",
            "           1       0.45      0.03      0.05      3286\n",
            "           2       0.30      0.06      0.10       815\n",
            "\n",
            "    accuracy                           0.91     43664\n",
            "   macro avg       0.56      0.36      0.37     43664\n",
            "weighted avg       0.86      0.91      0.87     43664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN\n",
        "Increase the number of layers in the CNN model to improve accuracy.\n",
        "Added an additional Conv1D layer and dense layers to increase the depth of the model, which may help improve accuracy. We can further adjust the architecture and hyperparameters as needed to achieve the desired performance."
      ],
      "metadata": {
        "id": "k_Ho1yV6ANKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define your features and target column\n",
        "X = data.drop('FIRE_SIZE_CLASS', axis=1)\n",
        "y = data['FIRE_SIZE_CLASS']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional but recommended)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the input data to match the expected input shape for CNN\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Define your neural network model with multiple convolutional and dense layers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Use 'softmax' for 7-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IfuXW4U4635",
        "outputId": "6d9346bb-0266-45e3-fa11-bdc03ef8a5f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5458/5458 [==============================] - 32s 5ms/step - loss: 0.3360 - accuracy: 0.9055 - val_loss: 0.3096 - val_accuracy: 0.9064\n",
            "Epoch 2/10\n",
            "5458/5458 [==============================] - 29s 5ms/step - loss: 0.3031 - accuracy: 0.9059 - val_loss: 0.2961 - val_accuracy: 0.9064\n",
            "Epoch 3/10\n",
            "5458/5458 [==============================] - 26s 5ms/step - loss: 0.2896 - accuracy: 0.9067 - val_loss: 0.2841 - val_accuracy: 0.9076\n",
            "Epoch 4/10\n",
            "5458/5458 [==============================] - 26s 5ms/step - loss: 0.2791 - accuracy: 0.9081 - val_loss: 0.2777 - val_accuracy: 0.9093\n",
            "Epoch 5/10\n",
            "5458/5458 [==============================] - 24s 4ms/step - loss: 0.2696 - accuracy: 0.9089 - val_loss: 0.2678 - val_accuracy: 0.9103\n",
            "Epoch 6/10\n",
            "5458/5458 [==============================] - 25s 5ms/step - loss: 0.2620 - accuracy: 0.9099 - val_loss: 0.2610 - val_accuracy: 0.9107\n",
            "Epoch 7/10\n",
            "5458/5458 [==============================] - 26s 5ms/step - loss: 0.2557 - accuracy: 0.9109 - val_loss: 0.2562 - val_accuracy: 0.9104\n",
            "Epoch 8/10\n",
            "5458/5458 [==============================] - 28s 5ms/step - loss: 0.2498 - accuracy: 0.9117 - val_loss: 0.2519 - val_accuracy: 0.9112\n",
            "Epoch 9/10\n",
            "5458/5458 [==============================] - 26s 5ms/step - loss: 0.2444 - accuracy: 0.9124 - val_loss: 0.2514 - val_accuracy: 0.9126\n",
            "Epoch 10/10\n",
            "5458/5458 [==============================] - 34s 6ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 0.2449 - val_accuracy: 0.9139\n",
            "1365/1365 [==============================] - 3s 2ms/step - loss: 0.2449 - accuracy: 0.9139\n",
            "Test Loss: 0.2449, Test Accuracy: 0.9139\n",
            "1365/1365 [==============================] - 2s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.95     39563\n",
            "           1       0.74      0.10      0.17      3286\n",
            "           2       0.79      0.19      0.31       815\n",
            "\n",
            "    accuracy                           0.91     43664\n",
            "   macro avg       0.82      0.43      0.48     43664\n",
            "weighted avg       0.90      0.91      0.88     43664\n",
            "\n"
          ]
        }
      ]
    }
  ]
}